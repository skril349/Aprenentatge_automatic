{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g1q1mnorfHwx"
   },
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "\n",
    "<div style=\"float: left; width: 50%;\">\n",
    "\n",
    "<img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\" align=\"left\">\n",
    "\n",
    "</div>\n",
    "\n",
    "<div style=\"float: right; width: 50%;\">\n",
    "\n",
    "<p style=\"margin: 0; padding-top: 22px; text-align:right;\">M2.991 ¬∑ Aprenentatge autom√†tic ¬∑ PAC2</p>\n",
    "\n",
    "<p style=\"margin: 0; text-align:right;\">2024-1 ¬∑ M√†ster universitari en Ci√®ncia de dades (Data science)</p>\n",
    "\n",
    "<p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudis d'Inform√†tica, Multim√®dia i Telecomunicaci√≥</p>\n",
    "\n",
    "</div>\n",
    "\n",
    "</div>\n",
    "\n",
    "<div style=\"width:100%;\">&nbsp;</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFTsh39afHwz"
   },
   "source": [
    "# PAC 3: M√®todes supervisats\n",
    "\n",
    "En aquesta pr√†ctica veurem diferents m√®todes supervisats i intentarem optimitzar diverses m√®triques. Observarem com els diferents models classifiquen les observacions i amb quins obtenim un millor rendiment. Despr√©s aplicarem tot el que hem apr√®s fins ara a un nou conjunt de dades, simulant un cas pr√†ctic real.\n",
    "\n",
    "1. [Exploraci√≥ d‚Äôalgorismes supervisats](#eje1) \\\n",
    "    1.1. [C√†rrega de dades](#eje10) \\\n",
    "    1.2. [Naive-Bayes](#eje11) \\\n",
    "    1.3. [An√†lisi Discriminant Lineal (LDA) i An√†lisi Discriminant Quadr√†tic (QDA)](#eje12) \\\n",
    "    1.4. [K ve√Øns m√©s propers (KNN)](#eje13) \\\n",
    "    1.5. [M√†quines de suport vectorial (SVM)](#eje14) \\\n",
    "    1.6. [Arbres de decisi√≥](#eje15) \n",
    "2. [Implementaci√≥ del cas pr√†ctic](#eje2)\\\n",
    "    2.1. [C√†rrega de dades](#eje20) \\\n",
    "    2.2. [An√†lisi Exploratori de Dades](#eje21) \\\n",
    "    2.3. [Preprocessament de Dades](#eje22) \\\n",
    "    2.4. [Modelitzaci√≥](#eje23) \n",
    "\n",
    "\n",
    "<u>Consideracions generals</u>:\n",
    "\n",
    "- La soluci√≥ plantejada no pot utilitzar m√®todes, funcions o par√†metres declarats **_deprecated_** en futures versions, amb l‚Äôexcepci√≥ de la c√†rrega de dades com s‚Äôindica posteriorment.\n",
    "- Aquesta PAC s‚Äôha de realitzar de forma **estrictament individual**. Qualsevol indici de c√≤pia ser√† penalitzat amb un suspens (D) per a totes les parts implicades i la possible avaluaci√≥ negativa de l‚Äôassignatura de forma √≠ntegra.\n",
    "- √âs necessari que l‚Äôestudiant indiqui **totes les fonts** que ha utilitzat per a la realitzaci√≥ de la PAC. Si no √©s aix√≠, es considerar√† que l‚Äôestudiant ha com√®s plagi, sent penalitzat amb un suspens (D) i la possible avaluaci√≥ negativa de l‚Äôassignatura de forma √≠ntegra.\n",
    "\n",
    "<u>Format del lliurament</u>:\n",
    "\n",
    "- Alguns exercicis poden suposar diversos minuts d‚Äôexecuci√≥, per la qual cosa el lliurament s‚Äôha de fer en **format notebook** i en **format HTML**, on es vegi el codi, els resultats i els comentaris de cada exercici. Es pot exportar el notebook a HTML des del men√∫ File $\\to$ Download as $\\to$ HTML.\n",
    "- Hi ha un tipus de cel¬∑la especial per albergar text. Aquest tipus de cel¬∑la us ser√† molt √∫til per respondre les diferents preguntes te√≤riques plantejades al llarg de l‚Äôactivitat. Per canviar el tipus de cel¬∑la a aquest tipus, al men√∫: Cell $\\to$ Cell Type $\\to$ Markdown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DSSB2tHkfHw0"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <strong>Nom i cognoms:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bn0ZMDyKfHw0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shap\n",
    "import copy\n",
    "import tqdm\n",
    "import torch\n",
    "import pickle\n",
    "import kagglehub\n",
    "import umap\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from torcheval.metrics.functional import binary_f1_score, binary_accuracy, binary_auroc\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EIkGtp_BfHw0"
   },
   "source": [
    "<a id='ej1'></a>\n",
    "# 1. Exploraci√≥ d‚Äôalgorismes supervisats\n",
    "\n",
    "## 1.1. C√†rrega de dades\n",
    "\n",
    "El conjunt de dades Fashion MNIST proporcionat per Zalando consta de 70.000 imatges amb 10 classes diferents de roba repartides uniformement. No obstant aix√≤, per a aquesta pr√†ctica utilitzarem √∫nicament un subconjunt de 5.000 imatges que consisteix en 1.000 imatges de 5 classes diferents.\n",
    "\n",
    "Les imatges tenen una resoluci√≥ de 28x28 p√≠xels en escala de grisos, per la qual cosa es poden representar utilitzant un vector de 784 posicions.\n",
    "\n",
    "El seg√ºent codi carregar√† les 5.000 imatges a la variable `images` i les corresponents etiquetes (en forma num√®rica) a la variable `labels`. Podem comprovar que la c√†rrega ha estat correcta obtenint les dimensions d‚Äôaquestes dues variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "id": "MPEdyuVLfHw1",
    "outputId": "34a46905-a29c-4263-9161-b2fd1efd6276"
   },
   "outputs": [],
   "source": [
    "with open(\"data.pickle\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "X = data[\"images\"]\n",
    "y = data[\"labels\"]\n",
    "n_classes = 5\n",
    "labels = [\"T-shirt\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\"]\n",
    "\n",
    "print(\"Vector Image Dimensions: {}\".format(X.shape))\n",
    "print(\"Vector Label Dimensions: {}\".format(y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "81-zMw2NfHw1"
   },
   "source": [
    "Amb el codi seg√ºent podem veure un exemple d‚Äôimatge de cadascuna de les classes. Per fer-ho, reajustem el vector de 784 dimensions que representa cada imatge en una matriu de mida 28x28 i la transposem per mostrar-la:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, n_classes, figsize=(10,10))\n",
    "\n",
    "idxs = [np.where(y == i)[0] for i in range(n_classes)]\n",
    "\n",
    "for i in range(n_classes):\n",
    "    k = np.random.choice(idxs[i])\n",
    "    ax[i].imshow(X[k].reshape(28, 28), cmap=\"gray\")\n",
    "    ax[i].set_title(\"{}\".format(labels[i]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <strong>Implementaci√≥:</strong> \n",
    "\n",
    "Dividiu el _dataset_ en dos subconjunts, __*train*__ (80% de les dades) i __*test*__ (20% de les dades). Nombreu els conjunts com: X_train, X_test, y_train, y_test. Utilitzeu l‚Äôopci√≥ `random_state = 24`.\n",
    "    \n",
    "Podeu utilitzar la implementaci√≥ `train_test_split` de `sklearn`.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Soluci√≥:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per tal de visualitzar els resultats de cada algorisme supervisat, reduirem el dataset anterior a dues dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = umap.UMAP(n_components=2, random_state=42)\n",
    "model.fit(X_train)\n",
    "X_train_projection = model.transform(X_train)\n",
    "X_test_projection = model.transform(X_test)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "for i in range(n_classes):\n",
    "    ax.scatter(X_test_projection[y_test == i,0], X_test_projection[y_test == i,1], s=3, label=labels[i])\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al llarg dels exercicis aprendrem a visualitzar gr√†ficament les fronteres de decisi√≥ que ens retornen els diferents models. Per fer-ho, utilitzarem la funci√≥ definida a continuaci√≥, que segueix els passos seg√ºents:\n",
    "\n",
    "1. Crear una meshgrid amb els valors m√≠nim i m√†xim de 'x' i 'y'.\n",
    "2. Predir el classificador amb els valors de la meshgrid.\n",
    "3. Fer un reshape de les dades per obtenir el format corresponent.\n",
    "4. Un cop fet aix√≤, ja podem generar el gr√†fic de les fronteres de decisi√≥ i afegir-hi els punts reals. Aix√≠ veurem les √†rees que el model considera que s√≥n d'una classe i les que considera que s√≥n d'una altra. Quan hi superposem els punts, podrem comprovar si els classifica correctament dins l'√†rea que els correspon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the meshgrid with the minimum and maximum values of the x and y axes\n",
    "x_min, x_max = X_test_projection[:, 0].min() - 1, X_test_projection[:, 0].max() + 1\n",
    "y_min, y_max = X_test_projection[:, 1].min() - 1, X_test_projection[:, 1].max() + 1\n",
    "\n",
    "# Define the function that will visualize the decision boundary\n",
    "def plot_decision_boundaries(model, X_test_projection, y_test):\n",
    "\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.05),\n",
    "                         np.arange(y_min, y_max, 0.05))\n",
    "\n",
    "    # Prediction by using all values of the meshgrid\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Define the colors (one for each class)\n",
    "    cmap_light = ListedColormap(['gainsboro','lightgreen','peachpuff','lightcyan', 'pink'])\n",
    "    cmap_bold = ['grey','g','sandybrown','c','palevioletred']\n",
    "\n",
    "    # Draw the borders\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "    # Draw the points\n",
    "    for i in range(n_classes):\n",
    "         plt.scatter(X_test_projection[y_test == i,0], X_test_projection[y_test == i,1], \n",
    "                     s=3, label=labels[i], c=cmap_bold[i])\n",
    "    plt.legend()\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2k77YKbhfHw2"
   },
   "source": [
    "<a id='ej11'></a>\n",
    "## 1.2. Gaussian Na√Øve Bayes (1 punt)\n",
    "\n",
    "El prop√≤sit d‚Äôaquest primer exercici √©s comprendre el funcionament de l‚Äôalgorisme Na√Øve-Bayes, un algorisme peculiar que es basa en el teorema de Bayes per calcular la probabilitat que una observaci√≥ pertanyi a cadascuna de les classes. Aquest model assumeix que les caracter√≠stiques d‚Äôentrada s√≥n independents entre si, fet que permet simplificar el c√†lcul de les probabilitats condicionals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sYiQpphdfHw2"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementaci√≥:</strong>\n",
    "\n",
    "1. **Entrena un Model de Na√Øve-Bayes:** Utilitza el conjunt de dades de _train_ per entrenar un model de Na√Øve-Bayes. Fes servir el classificador `GaussianNB` de la biblioteca `sklearn` per a aquest objectiu.\n",
    "\n",
    "2. **Calcula l'_Accuracy_ del Model:** Un cop entrenat el model, calcula la seva precisi√≥ (_accuracy_) tant en el conjunt de _train_ com en el de _test_. Aix√≤ et permetr√† avaluar com de b√© est√† funcionant el teu model.\n",
    "\n",
    "3. **Calcula la Matriu de Confusi√≥:** Utilitza el conjunt de _test_ per calcular la matriu de confusi√≥ del model. Aquesta matriu t‚Äôajudar√† a entendre millor els encerts i errors del teu classificador.\n",
    "\n",
    "4. **Representa Gr√†ficament la Frontera de Decisi√≥:** Finalment, visualitza la frontera de decisi√≥ del model utilitzant el conjunt de _test_. Pots fer aix√≤ amb l‚Äôajuda de la funci√≥ `plot_decision_boundary` que ja has creat pr√®viament.\n",
    "\n",
    "Per a realitzar aquests c√†lculs i visualitzacions, utilitza les funcions `accuracy_score` i `confusion_matrix` del paquet `metrics` de `sklearn`.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "44uFc_xEfHw2"
   },
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Soluci√≥:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6EB_a4o-fHw3"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>An√†lisi:</strong> \n",
    "  \n",
    "An√†lisi de l'exercici.\n",
    "\n",
    "   - Com s√≥n les fronteres de decisi√≥? T√© sentit que tinguin aquesta forma amb l'algorisme utilitzat?\n",
    "   - Com s√≥n les prediccions obtingudes sobre el conjunt de test?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mAwzg5BafHw3",
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<strong>Resposta:</strong>\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I32OtF0CfHw3"
   },
   "source": [
    "<a id='ej12'></a>\n",
    "## 1.3 An√†lisi Discriminant Lineal (LDA) i An√†lisi Discriminant Quadr√†tic (QDA) (1 punt)\n",
    "\n",
    "Ara analitzar√†s dos algorismes que es basen en la transformaci√≥ lineal de les caracter√≠stiques d‚Äôentrada per maximitzar la separaci√≥ entre les classes. Aquests models operen sota la suposici√≥ que les caracter√≠stiques segueixen una distribuci√≥ gaussiana. Aix√≤ et permetr√† calcular les probabilitats condicionals de cada classe. Amb aquests c√†lculs, assignar√†s a cada observaci√≥ la classe que presenti la probabilitat condicional m√©s gran."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LmyzyqT6fHw3"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementaci√≥:</strong>\n",
    "\n",
    "Segueix aquests passos amb el dataset d‚Äôentrenament (_train_):    \n",
    "    \n",
    "1. Entrena un model d‚ÄôAn√†lisi Discriminant Lineal (LDA) utilitzant el classificador `LinearDiscriminantAnalysis` de `sklearn`.\n",
    "2. Calcula l‚Äô_accuracy_ (precisi√≥) del model tant en les dades de _train_ com de _test_.\n",
    "3. Calcula la matriu de confusi√≥ utilitzant les dades de _test_.\n",
    "4. Representa gr√†ficament la frontera de decisi√≥ amb les dades de _test_.\n",
    "\n",
    "Aquestes accions t‚Äôajudaran a avaluar l‚Äôefic√†cia del model LDA en el teu conjunt de dades i a entendre millor com classifica les observacions.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QLxfTyOvfHw3"
   },
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Soluci√≥:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CWXabsd9fHw3"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>An√†lisi:</strong>\n",
    "\n",
    "1. Observa les fronteres de decisi√≥ que has generat. Reflexiona sobre la seva forma: s‚Äôajusten al que esperaries de l‚Äôalgorisme d‚ÄôAn√†lisi Discriminant Lineal (LDA)? Considera la naturalesa lineal de l‚Äôalgorisme i com aix√≤ influeix en la forma de les fronteres.\n",
    "2. Avalua les prediccions realitzades sobre el conjunt de test. Analitza la seva precisi√≥ i com es distribueixen respecte a les fronteres de decisi√≥. S√≥n coherents aquestes prediccions amb el que observes a les fronteres de decisi√≥?\n",
    "\n",
    "Aquestes reflexions et permetran comprendre millor l‚Äôefectivitat del model LDA i la seva adequaci√≥ per al conjunt de dades amb qu√® est√†s treballant.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_7v6A60kfHw3",
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<strong>Resposta:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5IEnCibfHw3"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementaci√≥:</strong>\n",
    "\n",
    "Realitza els passos seg√ºents amb el dataset d‚Äôentrenament (_train_):\n",
    "\n",
    "1. Entrena un model d‚ÄôAn√†lisi Discriminant Quadr√†tic (QDA) utilitzant el classificador `QuadraticDiscriminantAnalysis` de `sklearn`.\n",
    "2. Calcula l‚Äô_accuracy_ (precisi√≥) del model tant en les dades de _train_ com en les de _test_.\n",
    "3. Calcula la matriu de confusi√≥ utilitzant les dades de _test_.\n",
    "4. Representa gr√†ficament la frontera de decisi√≥ amb les dades de _test_.\n",
    "\n",
    "Aquests passos t‚Äôajudaran a avaluar com el model QDA es comporta amb el teu conjunt de dades i a entendre la seva capacitat per classificar i diferenciar entre les classes.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yhNPVO3CfHw3"
   },
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Soluci√≥:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aDneGeZhssYx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l50NzPaTssYx"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>An√†lisi:</strong>\n",
    "\n",
    "1. Examina les fronteres de decisi√≥ que has generat. Reflexiona sobre la seva forma: √©s coherent amb el que esperaries de l‚Äôalgorisme d‚ÄôAn√†lisi Discriminant Quadr√†tic (QDA)? Considera com la naturalesa quadr√†tica de l‚Äôalgorisme podria influir en la forma d‚Äôaquestes fronteres.\n",
    "2. Avalua les prediccions realitzades sobre el conjunt de test. Observa la seva precisi√≥ i com es distribueixen en relaci√≥ amb les fronteres de decisi√≥. S√≥n aquestes prediccions consistents amb les fronteres observades?\n",
    "3. Reflexiona sobre les difer√®ncies entre els algorismes LDA i QDA. En qu√® es diferencien en termes de sup√≤sits, enfocament i resultats en les teves dades?\n",
    "\n",
    "Aquesta an√†lisi et permetr√† comprendre les caracter√≠stiques i l‚Äôefic√†cia de tots dos models, LDA i QDA, i com s‚Äôapliquen al teu conjunt de dades.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pmRdVVp1ssYx"
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<strong>Resposta:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjEyHwXFfHw4"
   },
   "source": [
    "<a id='ej13'></a>\n",
    "## 1.4. KNN (1 punt)\n",
    "\n",
    "En aquest punt, entendr√†s el funcionament de l‚Äôalgorisme KNN (K-Nearest-Neighbor), que es basa en la proximitat dels punts de dades en un espai de caracter√≠stiques. Analitzar√†s els seus avantatges i desavantatges, i comprendr√†s com els par√†metres que el componen influeixen en el seu comportament.\n",
    "\n",
    "KNN √©s un algorisme de tipus supervisat basat en inst√†ncia. Aix√≤ significa:\n",
    "\n",
    "- Supervisat: El teu conjunt de dades d‚Äôentrenament est√† etiquetat amb la classe o resultat esperat.\n",
    "- Basat en inst√†ncia (_Lazy Learning_): L‚Äôalgorisme no apr√®n expl√≠citament un model, com en la Regressi√≥ Log√≠stica o els arbres de decisi√≥. En canvi, memoritza les inst√†ncies d‚Äôentrenament i les utilitza com a \"coneixement\" en la fase de predicci√≥.\n",
    "\n",
    "Per entendre com funciona KNN, segueix aquests passos:\n",
    "\n",
    "1. Calcula la dist√†ncia entre l‚Äô√≠tem a classificar i la resta d‚Äô√≠tems del dataset d‚Äôentrenament.\n",
    "2. Selecciona els \"k\" elements m√©s propers, √©s a dir, aquells amb la menor dist√†ncia, segons el tipus de dist√†ncia que utilitzis (euclidiana, cosinus, manhattan, etc).\n",
    "3. Realitza una \"votaci√≥ de majoria\" entre els k punts seleccionats: la classe que predomini en aquests punts decidir√† la classificaci√≥ final de l‚Äô√≠tem analitzat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TADnYVTPfHw4"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementaci√≥:</strong>\n",
    "\n",
    "Realitza els passos seg√ºents amb el dataset d‚Äôentrenament (_train_):\n",
    "\n",
    "1. Entrena un classificador KNN amb l‚Äôhiperpar√†metre `n_neighbors=2` utilitzant el classificador `KNeighborsClassifier` de `sklearn`.\n",
    "2. Calcula l‚Äô_accuracy_ (precisi√≥) del model tant en les dades de _train_ com en les de _test_.\n",
    "3. Calcula la matriu de confusi√≥ utilitzant les dades de _test_.\n",
    "4. Representa gr√†ficament la frontera de decisi√≥ amb les dades de _test_.\n",
    "\n",
    "Si en entrenar el classificador apareix un av√≠s (_warning_) i vols ignorar-lo, executa el codi seg√ºent abans de l‚Äôentrenament:\n",
    "\n",
    "`import warnings`  \n",
    "`warnings.filterwarnings('ignore', message='^.*will change.*$', category=FutureWarning)`\n",
    "\n",
    "Aix√≤ et permetr√† avaluar l‚Äôefectivitat del model KNN amb `n_neighbors=2` en el teu conjunt de dades i entendre com es comporta en termes de classificaci√≥ i separaci√≥ de classes.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NLjdWCM2fHw4"
   },
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Soluci√≥:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mQ50-Q15fHw4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tF_2dKwAfHw8"
   },
   "source": [
    "En el model que has entrenat, has fixat el par√†metre `n_neighbors` de manera arbitr√†ria. Tanmateix, √©s possible que amb un altre valor obtinguis una millor predicci√≥. Per trobar el valor √≤ptim dels par√†metres d‚Äôun model (_hyperparameter tuning_), sovint s‚Äôutilitza una cerca de graella (_grid search_). Aix√≤ implica entrenar un model per a cada combinaci√≥ possible d‚Äôhiperpar√†metres i avaluar-lo mitjan√ßant validaci√≥ creuada (_cross validation_) amb 5 particions estratificades. Posteriorment, seleccionar√†s la combinaci√≥ d‚Äôhiperpar√†metres que hagi obtingut els millors resultats.\n",
    "\n",
    "En aquest cas, et centrar√†s en optimitzar un sol hiperpar√†metre:\n",
    "\n",
    "- ùëò: el nombre de ve√Øns que es consideren per classificar un nou exemple. Has de provar amb tots els valors entre 1 i 20.\n",
    "\n",
    "Realitza aquest proc√©s per identificar el nombre √≤ptim de ve√Øns, fet que et permetr√† millorar la precisi√≥ de les teves prediccions amb el model KNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2UDe0lBofHw8"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <strong>Implementaci√≥:</strong>\n",
    "\n",
    "Per calcular el valor √≤ptim de l‚Äôhiperpar√†metre _k_ (`n_neighbors`), has de realitzar una cerca de graella amb validaci√≥ creuada. Aquest proc√©s t‚Äôajudar√† a trobar el valor √≤ptim de _k_. Per a cada valor, calcula la seva mitjana i desviaci√≥ est√†ndard. Despr√©s, implementa un _heatmap_ per visualitzar la precisi√≥ segons els diferents valors de l‚Äôhiperpar√†metre.\n",
    "\n",
    "Utilitza el m√≤dul `GridSearchCV` de `sklearn` per calcular el millor hiperpar√†metre. Per a la visualitzaci√≥ del _heatmap_, fes servir la biblioteca `Seaborn`.\n",
    "\n",
    "Aquests passos et permetran identificar de manera efectiva i visual el valor de _k_ que maximitza la precisi√≥ del teu model KNN.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h9Af8JcrfHw8"
   },
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Soluci√≥:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qb8GHGHOfHw8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKBqIrRJfHw8"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementaci√≥:</strong>\n",
    "\n",
    "Segueix aquests passos amb el dataset d‚Äôentrenament (_train_):\n",
    "\n",
    "1. Entrena un classificador KNN utilitzant el millor hiperpar√†metre que hagis trobat.\n",
    "2. Calcula l‚Äô_accuracy_ (precisi√≥) del model tant en les dades de _train_ com en les de _test_.\n",
    "3. Calcula la matriu de confusi√≥ utilitzant les dades de _test_.\n",
    "4. Representa gr√†ficament la frontera de decisi√≥ amb les dades de _test_.\n",
    "\n",
    "Aquest proc√©s et permetr√† veure com l‚Äôhiperpar√†metre √≤ptim que has identificat millora l‚Äôefic√†cia del teu model KNN en la classificaci√≥ de les dades.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hBI2kRH5fHw8"
   },
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Soluci√≥:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mK3awkbwfHw8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "teluDtnHfHw8"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>An√†lisi:</strong>\n",
    "\n",
    "1. Comenta els resultats obtinguts en la cerca del millor hiperpar√†metre. Reflexiona sobre com ha variat el rendiment del model amb els diferents valors de `n_neighbors`.\n",
    "2. Analitza com es visualitza gr√†ficament el canvi del valor de `n_neighbors`. Observes alguna tend√®ncia o patr√≥ clar? √âs coherent aquesta difer√®ncia entre els dos gr√†fics quan canvia el par√†metre?\n",
    "3. Examina les fronteres de decisi√≥ que has generat. T√© sentit la forma d‚Äôaquestes fronteres donat l‚Äôalgorisme KNN utilitzat? Pensa en com l‚Äôelecci√≥ del nombre de ve√Øns influeix en la forma de la frontera.\n",
    "4. Avalua les prediccions realitzades sobre el conjunt de test. Observa la seva precisi√≥ i com es distribueixen en relaci√≥ amb les fronteres de decisi√≥. S√≥n aquestes prediccions consistents amb el que observes a les fronteres de decisi√≥?\n",
    "\n",
    "Aquesta an√†lisi t‚Äôajudar√† a comprendre l‚Äôefic√†cia del model KNN amb diferents configuracions de `n_neighbors` i el seu impacte en la classificaci√≥ de les dades.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ET55syCqfHw8",
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<strong>Resposta:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UoWjLa8LfHw9"
   },
   "source": [
    "<a id='ej14'></a>\n",
    "## 1.5. SVM (1 punt)\n",
    "\n",
    "En aquesta secci√≥, explorar√†s les M√†quines de Vectors de Suport (SVM), que es basen en el concepte del _Maximal Margin Classifier_ i l‚Äôhiperpl√†.\n",
    "\n",
    "Un hiperpl√† en un espai p-dimensional es defineix com un subespai pla i af√≠ de dimensions p-1. En dues dimensions, √©s una recta; en tres, un pla convencional. Per a dimensions majors a tres, encara que no sigui intu√Øtiu de visualitzar, el concepte es mant√©.\n",
    "\n",
    "Quan els casos s√≥n perfectament separables de manera lineal, sorgeixen infinits possibles hiperplans. Per seleccionar el classificador √≤ptim, utilitza el concepte de _maximal margin hyperplane_, l‚Äôhiperpl√† que es troba m√©s allunyat de totes les observacions d‚Äôentrenament. Aquest es defineix calculant la dist√†ncia perpendicular m√≠nima (marge) de les observacions a un hiperpl√†. L‚Äôhiperpl√† √≤ptim √©s aquell que maximitza aquest marge.\n",
    "\n",
    "En el proc√©s d‚Äôoptimitzaci√≥, has de tenir en compte que nom√©s les observacions al marge o que el violen (vectors suport) influeixen en l‚Äôhiperpl√†. Aquests vectors suport s√≥n els que defineixen el classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WMxzknM5fHw9"
   },
   "source": [
    "#### Els _kernels_ en SVM\n",
    "\n",
    "En situacions on no pots trobar un hiperpl√† que separi dues classes, √©s a dir, quan les classes no s√≥n linealment separables, pots utilitzar el truc del nucli (_kernel trick_). Aquest m√®tode et permet treballar en una dimensi√≥ nova on √©s possible trobar un hiperpl√† per separar les classes.\n",
    "\n",
    "Igual que amb el KNN, les SVM tamb√© depenen de diversos hiperpar√†metres. En aquest cas, et centrar√†s en optimitzar dos hiperpar√†metres:\n",
    "\n",
    "1. **C**: la regularitzaci√≥, que √©s el valor de penalitzaci√≥ dels errors en la classificaci√≥. Aquest valor indica el comprom√≠s entre obtenir l‚Äôhiperpl√† amb el marge m√©s gran possible i classificar correctament el m√†xim nombre d‚Äôexemples. Has de provar els valors seg√ºents: 0.01, 0.1, 1, 10, 50, 100 i 200.\n",
    "   \n",
    "2. **Gamma**: un coeficient que multiplica la dist√†ncia entre dos punts en el kernel radial. En termes simples, com m√©s petit sigui gamma, m√©s influ√®ncia tindran dos punts propers. Has de provar els valors: 0.001, 0.01, 0.1, 1 i 10.\n",
    "\n",
    "Per validar el rendiment de l‚Äôalgorisme amb cada combinaci√≥ d‚Äôhiperpar√†metres, utilitza la validaci√≥ creuada (_cross-validation_) amb 4 particions estratificades."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UdHJe2affHw9"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <strong>Implementaci√≥:</strong>\n",
    "\n",
    "\n",
    "1. Calcula el valor √≤ptim dels hiperpar√†metres _C_ i _gamma_ utilitzant una cerca de graella amb validaci√≥ creuada. Aquest proc√©s t‚Äôajudar√† a trobar els valors √≤ptims.\n",
    "2. Per a cada combinaci√≥ de valors, calcula la seva mitjana i desviaci√≥ est√†ndard.\n",
    "3. Fes un _heatmap_ per visualitzar la precisi√≥ segons els diferents valors dels hiperpar√†metres.\n",
    "\n",
    "Utilitza el m√≤dul `GridSearchCV` de `sklearn` per calcular els millors hiperpar√†metres amb el classificador SVC (de `SVM` de `sklearn`). Per a la visualitzaci√≥ del _heatmap_, fes servir la biblioteca `Seaborn`.\n",
    "\n",
    "Aquests passos et permetran identificar de manera efectiva i visual els valors de _C_ i _gamma_ que maximitzen la precisi√≥ del teu model SVM.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "em56OnxofHw9"
   },
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Soluci√≥:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eBxQod7LfHw9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_E-ae6x0fHw9"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementaci√≥:</strong>\n",
    "\n",
    "Realitza els passos seg√ºents amb el dataset d‚Äôentrenament (_train_):\n",
    "\n",
    "1. Entrena un model SVM utilitzant la millor combinaci√≥ de par√†metres que hagis trobat.\n",
    "2. Calcula l‚Äô_accuracy_ (precisi√≥) del model tant en les dades de _train_ com en les de _test_.\n",
    "3. Calcula la matriu de confusi√≥ utilitzant les dades de _test_.\n",
    "4. Representa gr√†ficament la frontera de decisi√≥ amb les dades de _test_.\n",
    "\n",
    "Aquest proc√©s et permetr√† veure com la millor combinaci√≥ de par√†metres millora l‚Äôefic√†cia del teu model SVM en la classificaci√≥ de les dades.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "maHfaJpAfHw9"
   },
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Soluci√≥:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qf2kQHuMfHw9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oT7FOpk9fHw9"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>An√†lisi:</strong>\n",
    "\n",
    "1. Comenta els resultats obtinguts en la cerca dels millors hiperpar√†metres. Reflexiona sobre com ha variat el rendiment del model SVM amb els diferents valors de _C_ i _gamma_. Considera si els valors √≤ptims trobats tenen sentit en el context del teu conjunt de dades.\n",
    "2. Examina les fronteres de decisi√≥ que has generat amb el model SVM. √âs coherent la forma d‚Äôaquestes fronteres amb el que esperaries de l‚Äôalgorisme utilitzat? Pensa en com la combinaci√≥ d‚Äôhiperpar√†metres seleccionats podria influir en la forma de les fronteres.\n",
    "3. Avalua les prediccions realitzades sobre el conjunt de test. Observa la seva precisi√≥ i com es distribueixen en relaci√≥ amb les fronteres de decisi√≥. S√≥n aquestes prediccions consistents amb el que observes a les fronteres de decisi√≥?\n",
    "\n",
    "Aquesta an√†lisi t‚Äôajudar√† a comprendre l‚Äôefic√†cia del model SVM amb els hiperpar√†metres seleccionats i el seu impacte en la classificaci√≥ de les dades.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kan9R0kpfHw9",
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<strong>Resposta:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x9Z1MzFbfHw9"
   },
   "source": [
    "<a id='ej15'></a>\n",
    "## 1.6. Arbres de decisi√≥ (1 punt)\n",
    "\n",
    "En aquesta secci√≥, explorar√†s els arbres de decisi√≥, models predictius que es basen en regles bin√†ries (s√≠/no) per classificar les observacions segons els seus atributs i predir el valor de la variable resposta. Aquests arbres poden ser classificadors, com en el teu exemple, o regressors per predir variables cont√≠nues.\n",
    "\n",
    "#### Construcci√≥ d‚Äôun Arbre\n",
    "\n",
    "Per construir un arbre, segueix l‚Äôalgorisme de *recursive binary splitting*:\n",
    "\n",
    "1. Comen√ßa a la part superior de l‚Äôarbre, on totes les observacions pertanyen a la mateixa regi√≥.\n",
    "2. Identifica tots els possibles punts de tall per a cadascun dels predictors. Aquests punts de tall s√≥n els diferents nivells dels predictors.\n",
    "3. Avalua les possibles divisions per a cada predictor utilitzant una mesura espec√≠fica. En els classificadors, aquestes mesures poden ser el *classification error rate*, l‚Äô√≠ndex Gini, l‚Äôentropia o el chi-square.\n",
    "\n",
    "Comprendre aquests passos t‚Äôajudar√† a entendre com els arbres de decisi√≥ creen divisions bin√†ries per classificar les dades i com es poden aplicar tant per a classificaci√≥ com per a regressi√≥."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wTnIbWTYfHw9"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementaci√≥n:</strong>\n",
    "\n",
    "Sigue estos pasos:\n",
    "\n",
    "1. Con el dataset de entrenamiento (_train_), entrena un √°rbol de decisi√≥n utilizando el clasificador `DecisionTreeClassifier` de la biblioteca `tree` de `sklearn`.\n",
    "2. Calcula el _accuracy_ (precisi√≥n) del modelo tanto en los datos de _train_ como de _test_.\n",
    "3. Calcula la matriz de confusi√≥n utilizando los datos de _test_.\n",
    "4. Representa gr√°ficamente la frontera de decisi√≥n con los datos de _test_.\n",
    "5. Representa el √°rbol de decisi√≥n. Puedes utilizar el comando `plot.tree` de la biblioteca `tree` de `sklearn`.\n",
    "\n",
    "Estos pasos te permitir√°n evaluar c√≥mo el √°rbol de decisi√≥n se comporta en tu conjunto de datos, tanto en t√©rminos de clasificaci√≥n como en su representaci√≥n visual.\"\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zpPKYCZjfHw-"
   },
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Soluci√≥:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kqqvClsEfHw-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PI_q3bCafHw-"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>An√†lisi:</strong>\n",
    "\n",
    "1. **Avalua i comenta els resultats:** Analitza l‚Äô_accuracy_ del model en els conjunts de _train_ i _test_. Si el model t√© un _accuracy_ molt alt en _train_ per√≤ significativament m√©s baix en _test_, aix√≤ pot indicar overfitting. A m√©s, revisa la matriu de confusi√≥ per identificar si hi ha desequilibris en les classificacions correctes i errors per classe.\n",
    "\n",
    "2. **Reflexiona sobre la frontera de decisi√≥:** Observa si la frontera de decisi√≥ al conjunt de _test_ mostra patrons abruptes o sobrecomplexos. Aquesta caracter√≠stica √©s coherent amb el que esperaries d‚Äôun arbre de decisi√≥, especialment si est√† profundament ajustat al conjunt de _train_.\n",
    "\n",
    "3. **Observa la representaci√≥ gr√†fica de l‚Äôarbre:** Analitza com les ramificacions mostren les decisions preses pel model. Busca si hi ha nodes fulla amb un nombre molt redu√Øt d‚Äôobservacions o divisions molt espec√≠fiques que podrien indicar sobreajustament. Comprova si les regles de classificaci√≥ s√≥n intu√Øtives i si reflecteixen els patrons esperats en el conjunt de dades.\n",
    "\n",
    "Aquesta an√†lisi t‚Äôajudar√† a identificar possibles ajustaments al model per millorar la seva capacitat de generalitzaci√≥ i la seva efic√†cia global.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MABFtjLJfHw-",
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<strong>Resposta:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GlU7Tg-1fHw-"
   },
   "source": [
    "#### Evitant el *overfitting*\n",
    "\n",
    "El proc√©s de construcci√≥ d‚Äôarbres descrit tendeix a reduir r√†pidament l‚Äôerror d‚Äôentrenament, de manera que, generalment, el model s‚Äôajusta molt b√© a les observacions utilitzades com a entrenament (conjunt de *train*). Com a conseq√º√®ncia, els arbres de decisi√≥ tendeixen a l‚Äô*overfitting*.\n",
    "   \n",
    "Per evitar l‚Äô*overfitting* en els arbres de decisi√≥, √©s crucial que modifiquis certs hiperpar√†metres del model de la manera seg√ºent:\n",
    "\n",
    "1. Utilitza l‚Äôhiperpar√†metre `max_depth`, que defineix la profunditat m√†xima de l‚Äôarbre. Haur√†s d‚Äôexplorar els valors entre 4 i 10 per trobar l‚Äôequilibri adequat entre la complexitat del model i la seva capacitat per generalitzar.\n",
    "2. Estableix l‚Äôhiperpar√†metre `min_samples_split`, que √©s el nombre m√≠nim d‚Äôobservacions que ha de tenir una fulla de l‚Äôarbre abans de considerar una divisi√≥. Experimenta amb valors com 2, 10, 20, 50 i 100 per assegurar-te que l‚Äôarbre no es torni massa espec√≠fic per a les observacions d‚Äôentrenament.\n",
    "\n",
    "Ajustant aquests hiperpar√†metres, podr√†s controlar la tend√®ncia de l‚Äôarbre de decisi√≥ a sobreajustar-se al conjunt d‚Äôentrenament, millorant aix√≠ la seva capacitat per fer prediccions efectives en dades noves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o2KF6CI2fHw-"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <strong>Implementaci√≥:</strong>\n",
    "\n",
    "1. Calcula el valor √≤ptim dels hiperpar√†metres `max_depth` i `min_samples_split` utilitzant una cerca de graella amb validaci√≥ creuada. Aquest proc√©s t‚Äôajudar√† a trobar els valors √≤ptims que evitaran el sobreajustament.\n",
    "2. Per a cada combinaci√≥ de valors, calcula la seva mitjana i desviaci√≥ est√†ndard.\n",
    "3. Fes un _heatmap_ per visualitzar la precisi√≥ segons els diferents valors dels hiperpar√†metres.\n",
    "\n",
    "Utilitza el m√≤dul `GridSearchCV` de `sklearn` per calcular els millors hiperpar√†metres amb el classificador `DecisionTreeClassifier` de `tree` de `sklearn`. Per a la visualitzaci√≥ del _heatmap_, fes servir la biblioteca `Seaborn`.\n",
    "\n",
    "Aquests passos et permetran identificar de manera efectiva i visual els valors de `max_depth` i `min_samples_split` que maximitzen la precisi√≥ del teu arbre de decisi√≥, minimitzant el risc de sobreajustament.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RcaZzrK-fHw-"
   },
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Soluci√≥:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DT9ttV8GfHw-"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementaci√≥:</strong>\n",
    "\n",
    "\n",
    "1. Entrena un arbre de decisi√≥ amb el dataset d‚Äôentrenament (_train_) utilitzant la millor combinaci√≥ de par√†metres que hagis trobat.\n",
    "2. Calcula l‚Äô_accuracy_ (precisi√≥) del model tant en les dades de _train_ com en les de _test_.\n",
    "3. Calcula la matriu de confusi√≥ utilitzant les dades de _test_.\n",
    "4. Representa gr√†ficament la frontera de decisi√≥ amb les dades de _test_.\n",
    "5. Representa l‚Äôarbre de decisi√≥.\n",
    "\n",
    "Aquests passos et permetran avaluar com l‚Äôarbre de decisi√≥, ajustat amb els hiperpar√†metres √≤ptims, es comporta en el teu conjunt de dades, tant en termes de classificaci√≥ com en la seva representaci√≥ visual.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xRxJyG5MfHw-"
   },
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Soluci√≥:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-cQKFNpffHw-"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>An√†lisi:</strong>\n",
    "\n",
    "1. Avalua i comenta els resultats obtinguts en la cerca dels millors hiperpar√†metres. Considera com la combinaci√≥ √≤ptima de `max_depth` i `min_samples_split` ha impactat en el rendiment de l‚Äôarbre de decisi√≥.\n",
    "2. Examina les fronteres de decisi√≥ generades amb el conjunt de _test_. Reflexiona si la forma d‚Äôaquestes fronteres √©s coherent amb el que esperaries d‚Äôun arbre de decisi√≥ configurat amb aquests hiperpar√†metres.\n",
    "3. Analitza les prediccions realitzades sobre el conjunt de _test_. Observa la seva precisi√≥ i com es distribueixen en relaci√≥ amb les fronteres de decisi√≥. S√≥n consistents aquestes prediccions amb l‚Äôestructura de l‚Äôarbre de decisi√≥ i les fronteres observades?\n",
    "\n",
    "Aquesta an√†lisi t‚Äôajudar√† a comprendre l‚Äôefic√†cia de l‚Äôarbre de decisi√≥ amb els hiperpar√†metres seleccionats i el seu impacte en la classificaci√≥ de les dades.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y3vL6gWjfHw_",
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<strong>Resposta:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1N8TJl-1fHw_"
   },
   "source": [
    "<a id='eje2'></a>\n",
    "# 2. Implementaci√≥ del cas pr√†ctic (5 punts)\n",
    "\n",
    "Avui dia, la log√≠stica de l‚Äô√∫ltima milla √©s un problema abordat a la ind√∫stria per moltes empreses dedicades al comer√ß electr√≤nic. La informaci√≥ proporcionada a l‚Äôusuari a l‚Äôhora de fer una comanda pot suposar un valor diferencial. Per aix√≤, moltes empreses dediquen molts recursos per oferir una estimaci√≥ precisa sobre el temps que trigar√† a arribar cada comanda. En aquest exercici ens centrarem a predir el nivell de servei de les operacions log√≠stiques de l‚Äô√∫ltima milla d‚ÄôAmazon. En concret, identificarem aquelles entregues que es considerin premium (temps de repartiment inferior a dues hores).\n",
    "\n",
    "Per fer-ho, utilitzarem el conjunt de dades d‚Äôentregues [amazon-delivery-dataset](https://www.kaggle.com/datasets/sujalsuthar/amazon-delivery-dataset), el qual inclou dades sobre m√©s de 43.632 entregues en diverses ciutats, amb informaci√≥ rellevant sobre els detalls de la comanda, els agents de lliurament, les condicions meteorol√≤giques i del tr√†nsit, i les m√®triques de rendiment del lliurament. En concret, el dataset cont√© 16 caracter√≠stiques:\n",
    "\n",
    "- Order_ID: identificador √∫nic de comanda\n",
    "- Agent_Age: edat de l‚Äôagent (repartidor)\n",
    "- Agent_Rating: puntuaci√≥ de l‚Äôagent (repartidor)\n",
    "- Store_Latitude: latitud del magatzem o botiga\n",
    "- Store_Longitude: longitud del magatzem o botiga\n",
    "- Drop_Latitude: latitud del client\n",
    "- Drop_Longitude: longitud del client\n",
    "- Order_Date: data de la comanda\n",
    "- Order_Time: hora de la comanda\n",
    "- Pickup_Time: hora a la qual la comanda va ser recollida per al seu lliurament\n",
    "- Weather: informaci√≥ sobre la climatologia\n",
    "- Traffic: informaci√≥ sobre el tr√†nsit\n",
    "- Vehicle: informaci√≥ sobre el vehicle\n",
    "- Area: informaci√≥ sobre l‚Äô√†rea de repartiment\n",
    "- Category: categoria dels productes de la comanda\n",
    "- Delivery_Time: temps de lliurament (minuts)\n",
    "\n",
    "L‚Äôobjectiu d‚Äôaquesta secci√≥ √©s abordar l‚Äôan√†lisi d‚Äôaquest conjunt de dades i entrenar una xarxa neuronal (Perceptr√≥ Multicapa) per predir el nivell de servei. Aqu√≠ tens alguns passos que podries seguir:\n",
    "\n",
    "1. **An√†lisi Exploratori de Dades (EDA)**: Comen√ßa explorant el conjunt de dades per entendre‚Äôn l‚Äôestructura i distribuci√≥. Analitza la proporci√≥ de cada classe. Observa la distribuci√≥ de les diferents caracter√≠stiques i la seva relaci√≥ amb la classe objectiu \"class\".\n",
    "\n",
    "2. **Preprocessament de Dades**: Considera normalitzar les caracter√≠stiques perqu√® estiguin a la mateixa escala que les components principals.\n",
    "\n",
    "3. **Modelitzaci√≥**: Utilitza un perceptr√≥ multicapa com a eina de classificaci√≥. At√®s que l‚Äôobjectiu √©s identificar el nivell de servei del lliurament, √©s vital centrar-se en m√®triques com la precisi√≥, la sensibilitat (_recall_), el valor F1 i l‚Äô√†rea sota la corba ROC (AUC-ROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SAn2GmJcfHw_"
   },
   "source": [
    "<a id='ej20'></a>\n",
    "## 2.1. C√†rrega de dades i processament inicial (0.5 punts)\n",
    "\n",
    "El primer que has de fer √©s carregar el conjunt de dades i visualitzar informaci√≥ rellevant del mateix. Assegura‚Äôt de verificar el seg√ºent:\n",
    "\n",
    "1. Confirma la quantitat total de files i columnes al DataFrame.\n",
    "2. Revisa el nom de cada columna del DataFrame.\n",
    "3. Verifica el nombre de valors no nuls en cada columna.\n",
    "4. Identifica el tipus de dades de cada columna, que pot ser int, float, object, entre d‚Äôaltres.\n",
    "5. Comprova la quantitat de mem√≤ria utilitzada pel DataFrame.\n",
    "\n",
    "Aquests passos et proporcionaran una comprensi√≥ inicial clara i detallada del conjunt de dades amb el qual est√†s treballant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = kagglehub.dataset_download(\"sujalsuthar/amazon-delivery-dataset\")\n",
    "dataset_path = os.path.join(root_path, \"amazon_delivery.csv\") \n",
    "data = pd.read_csv(dataset_path)\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementaci√≥:</strong>\n",
    "\n",
    "Com es pot observar, no disposem del nivell de servei en el conjunt de dades. Per aix√≤, definirem que totes les entregues realitzades en un m√†xim de dues hores han tingut un servei Premium. Per fer-ho, crea una nova columna denominada \"Premium_Delivery\", que contingui el valor 1 si l‚Äôentrega s‚Äôha realitzat en un m√†xim de 120 minuts, i un 0 en cas contrari. √âs important assegurar que el tipus de la nova columna sigui enter.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Soluci√≥:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementaci√≥:</strong>\n",
    "\n",
    "Per simplificar l‚Äôexercici i facilitar-ne la comprensi√≥, s‚Äôhan d‚Äôeliminar les seg√ºents columnes: Order_ID, Order_Date, Order_Time i Pickup_Time.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Soluci√≥:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementaci√≥:</strong>\n",
    "    \n",
    "A continuaci√≥, calcularem la dist√†ncia haversiana en quil√≤metres entre el magatzem i el client. Per fer-ho, hem de crear una nova columna anomenada \"Distance\" i eliminar les quatre columnes relacionades amb les coordenades.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Soluci√≥:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nwJqa9WIfHw_"
   },
   "source": [
    "<a id='ej21'></a>\n",
    "## 2.2. An√†lisi Exploratori de Dades (EDA) (1.25 punts)\n",
    "\n",
    "L‚ÄôAn√†lisi Exploratori de Dades (EDA, per les seves sigles en angl√®s) en ci√®ncia de dades √©s un enfocament inicial per comprendre i resumir el contingut d‚Äôun conjunt de dades. Aquest proc√©s implica diverses t√®cniques i passos:\n",
    "\n",
    "1. **Inspecci√≥ de Dades**: Es comen√ßa revisant les dades brutes per identificar-ne l‚Äôestructura, la mida i el tipus (com num√®ric, categ√≤ric). Aix√≤ inclou detectar valors faltants o inusuals.\n",
    "\n",
    "2. **Resum Estad√≠stic**: Es calculen estad√≠stiques descriptives com la mitjana, mediana, rang, vari√†ncia i desviaci√≥ est√†ndard per obtenir una idea general de les tend√®ncies i patrons en les dades.\n",
    "\n",
    "3. **Visualitzaci√≥ de Dades**: S‚Äôutilitzen gr√†fics i diagrames (com histogrames, gr√†fics de caixa, diagrames de dispersi√≥) per visualitzar distribucions, relacions entre variables i possibles anomalies. Aix√≤ ajuda a comprendre millor les dades i a identificar patrons o irregularitats.\n",
    "\n",
    "4. **An√†lisi de Relacions i Correlacions**: S‚Äôexploren les relacions entre diferents variables per entendre com s‚Äôinflueixen entre si. Aix√≤ pot implicar l‚Äô√∫s de matrius de correlaci√≥ i gr√†fics de dispersi√≥.\n",
    "\n",
    "5. **Identificaci√≥ de Patrons i Anomalies**: Es busquen patrons consistents o anomalies (com valors at√≠pics) que puguin suggerir tend√®ncies o problemes en les dades.\n",
    "\n",
    "L‚ÄôEDA √©s una fase cr√≠tica en qualsevol projecte de ci√®ncia de dades, ja que proporciona una comprensi√≥ profunda i una base s√≤lida per a posteriors an√†lisis i modelatge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pIX-1GizfHw_",
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementaci√≥:</strong>\n",
    "\n",
    "1. Calcula les freq√º√®ncies de la variable objectiu (`Premium_Delivery`) en el teu conjunt de dades. \n",
    "2. Crea un gr√†fic de barres per visualitzar aquestes freq√º√®ncies. Aix√≤ t‚Äôajudar√† a entendre la proporci√≥ d‚Äôentregues premium en comparaci√≥ amb les que no ho s√≥n.\n",
    "\n",
    "A continuaci√≥, analitza la distribuci√≥ de les variables num√®riques:\n",
    "\n",
    "1. Representa gr√†ficament l‚Äôhistograma de les variables, separant les observacions segons la classe a la qual pertanyen (premium o no).\n",
    "2. Organitza tots els histogrames en un format de 4 files i 1 columna. Aix√≤ facilitar√† la comparaci√≥ visual de les distribucions per a cada classe en cada variable.\n",
    "\n",
    "Per √∫ltim, analitza la distribuci√≥ de les variables categ√≤riques de forma an√†loga a les variables num√®riques, organitzant tots els histogrames en un format de 5 files i 1 columna.\n",
    "\n",
    "Aquests passos et permetran obtenir una visi√≥ m√©s clara de l‚Äôestructura del teu conjunt de dades i com les diferents variables poden influir en la identificaci√≥ de les entregues premium.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-MFH2nvWfHw_"
   },
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Soluci√≥:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7rDxe75IfHw_"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>An√†lisi:</strong>\n",
    "\n",
    "1. **Avalua la relaci√≥ de les freq√º√®ncies de la variable `Premium_Delivery`:** Reflexiona sobre com es distribueixen les transaccions entre premium i no premium. √âs la distribuci√≥ significativament desigual? Qu√® implica aix√≤ per a l‚Äôan√†lisi i la modelitzaci√≥ de les dades?\n",
    "\n",
    "2. **Analitza la informaci√≥ proporcionada pels histogrames de les variables descriptives:** Observa si hi ha difer√®ncies notables en les distribucions d‚Äôaquestes variables entre les classes. Pregunta‚Äôt: Hi ha variables que mostrin patrons diferents per al nivell de servei?\n",
    "\n",
    "3. **Considera altres formes de visualitzaci√≥:** Podrien ser √∫tils altres tipus de gr√†fics per entendre millor les dades? Per exemple:\n",
    "   - **Diagrames de caixa (boxplots):** Podrien ser √∫tils per visualitzar la distribuci√≥ de les variables en ambdues classes i identificar valors at√≠pics.\n",
    "   - **Mapa de calor de la matriu de correlaci√≥:** Pot ajudar a entendre les relacions entre les variables i identificar possibles agrupacions o depend√®ncies entre elles.\n",
    "\n",
    "Aquest an√†lisi t‚Äôajudar√† a obtenir una comprensi√≥ m√©s profunda de la naturalesa de les teves dades i a identificar possibles caracter√≠stiques que podrien ser importants per detectar les entregues premium.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oHW_jgcbfHw_",
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<strong>Resposta:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oa3HbpukfHw_"
   },
   "source": [
    "<a id='ej22'></a>\n",
    "## 2.3. Preprocessament de Dades (1.25 punts)\n",
    "\n",
    "El preprocessament de dades en ci√®ncia de dades √©s un pas crucial que implica la preparaci√≥ i transformaci√≥ de dades brutes en un format adequat per a la seva posterior an√†lisi i modelatge. Aquest proc√©s inclou diverses tasques essencials:\n",
    "\n",
    "1. **Neteja de Dades**: S‚Äôeliminen o corregeixen dades err√≤nies, incompletes, inexactes o irrellevants. Aix√≤ pot incloure tractar amb valors faltants, corregir errors d‚Äôentrada i gestionar outliers.\n",
    "\n",
    "2. **Normalitzaci√≥ i Escalat**: Les dades es transformen perqu√® estiguin en una escala comuna, sense distorsionar difer√®ncies en els rangs de valors ni perdre informaci√≥. Per exemple, escalat min-max o estandarditzaci√≥.\n",
    "\n",
    "3. **Codificaci√≥ de Variables Categ√≤riques**: Les variables categ√≤riques (com g√®nere o pa√≠s) es converteixen en formats num√®rics perqu√® puguin ser processades per algorismes d‚Äôaprenentatge autom√†tic, utilitzant t√®cniques com codificaci√≥ one-hot o codificaci√≥ d‚Äôetiquetes.\n",
    "\n",
    "4. **Divisi√≥ de Dades**: Les dades es divideixen en conjunts d‚Äôentrenament, validaci√≥ i prova, permetent entrenar models, ajustar hiperpar√†metres i avaluar el rendiment del model de manera efectiva.\n",
    "\n",
    "5. **Gesti√≥ de Dades Desbalancejades**: En casos de conjunts de dades desbalancejats, s‚Äôapliquen t√®cniques com sobremostreig o submostreig per assegurar que el model no estigui esbiaixat cap a la classe m√©s freq√ºent.\n",
    "\n",
    "6. **Enginyeria de Caracter√≠stiques**: Es creen noves variables (caracter√≠stiques) a partir de les dades existents per millorar la capacitat del model per aprendre patrons i fer prediccions.\n",
    "\n",
    "El preprocessament √©s essencial per millorar la qualitat de les dades i fer-les m√©s adequades i efectives per a l‚Äôan√†lisi i el modelatge en projectes de ci√®ncia de dades."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementaci√≥:</strong> elimina els atributs categ√≤rics del conjunt de dades i, en el seu lloc, introdueix la transformaci√≥ d‚Äôaquests atributs a tantes variables bin√†ries com categories tinguin. √âs important que les noves columnes generades siguin de tipus enter. Recorda que la codificaci√≥ one-hot converteix les etiquetes categ√≤riques en vectors binaris. En aquests vectors, el valor de 1 s‚Äôassigna a la posici√≥ corresponent a la classe i el valor de 0 a totes les altres posicions. Aix√≤ facilita que els models d‚Äôaprenentatge autom√†tic processin i entenguin les etiquetes categ√≤riques.\n",
    "<hr>\n",
    "Suggeriment: utilitzeu la funci√≥ \"get_dummies\" de \"pandas\".\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Soluci√≥:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementaci√≥:</strong>\n",
    "\n",
    "A la primera secci√≥ de l‚Äôexercici vam observar que la columna `Agent_Rating` tenia un nombre redu√Øt de valors nuls. En aquest exercici hem d‚Äôimputar els valors nuls pel valor m√≠nim de la columna i verificar que cap columna addicional t√© valors nuls.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Soluci√≥:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iu0SHBWbfHxA"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementaci√≥:</strong>\n",
    "\n",
    "Ara dividirem el conjunt de dades. Per fer-ho, segueix aquests passos:\n",
    "\n",
    "1. Separa els descriptors de la variable resposta. Assigna els descriptors al conjunt `X` i la variable resposta al conjunt `y`.\n",
    "2. Elimina del conjunt de descriptors la columna `Delivery_Time`, ja que va ser utilitzada per calcular la nostra variable resposta.\n",
    "3. Divideix el _dataset_ en dos subconjunts: un per a entrenament (_train_) i un altre per a proves (_test_). Assigna el 80% de les dades al conjunt d‚Äôentrenament (`X_train`, `y_train`) i el 20% al conjunt de proves (`X_test`, `y_test`). Utilitza la funci√≥ `train_test_split` de la biblioteca `model_selection` de `sklearn`. Assegura‚Äôt d‚Äôutilitzar `random_state = 24` i fes una divisi√≥ estratificada per mantenir la mateixa proporci√≥ de classes en ambd√≥s conjunts.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K0e2C3NzfHxA"
   },
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Soluci√≥:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKCW1Rh1fHxA"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementaci√≥:</strong>\n",
    "\n",
    "1. Normalitza els descriptors utilitzant el `StandardScaler` de `sklearn`. Aix√≤ estandarditzar√† les caracter√≠stiques restant la mitjana i dividint per la desviaci√≥ est√†ndard.\n",
    "2. Mostra les dimensions del conjunt de descriptors original, del conjunt d‚Äôentrenament i del conjunt de prova. Aix√≤ et permetr√† veure com s‚Äôhan dividit les dades.\n",
    "\n",
    "<strong>Nota:</strong> Ajusta el `StandardScaler` √∫nicament amb els descriptors d‚Äôentrenament per evitar la fuga d‚Äôinformaci√≥ o 'data leakage'. La fuga d‚Äôinformaci√≥ ocorre quan s‚Äôutilitza informaci√≥ del conjunt de prova o validaci√≥ en el proc√©s d‚Äôajust del model. √âs a dir, si ajustes el model d‚Äôescalat amb tot el conjunt de dades, estaries utilitzant informaci√≥ del conjunt de prova o validaci√≥ en l‚Äôajust, fet que podria donar la impressi√≥ que el model √©s m√©s prec√≠s del que realment √©s. Per tant, assegura‚Äôt d‚Äôajustar el `StandardScaler` nom√©s amb les dades d‚Äôentrenament i despr√©s aplicar-lo als conjunts d‚Äôentrenament i prova.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rxe-T3-mfHxA"
   },
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Soluci√≥:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementaci√≥:</strong>\n",
    "\n",
    "Converteix els conjunts de dades d‚Äôentrenament i prova en tensors utilitzant el m√®tode `tensor` de la biblioteca `PyTorch`.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Soluci√≥:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cpg-RIGpfHxA"
   },
   "source": [
    "<a id='ej23'></a>\n",
    "## 2.4. Modelitzaci√≥ (2 punts)\n",
    "\n",
    "El MLP (Perceptr√≥ Multicapa) √©s, sens dubte, una eina poderosa en el camp de l‚Äôaprenentatge autom√†tic i la intel¬∑lig√®ncia artificial. Pot manejar tasques de classificaci√≥ i regressi√≥, fet que el fa vers√†til per a una varietat de problemes. La seva capacitat per modelar relacions no lineals complexes el converteix en una elecci√≥ popular quan les dades no segueixen patrons lineals simples.\n",
    "\n",
    "Aqu√≠ hi ha alguns punts clau sobre el MLP:\n",
    "\n",
    "- **Capes i Neurones**: El MLP consta de m√∫ltiples capes de neurones, que inclouen una capa d‚Äôentrada, una o m√©s capes ocultes i una capa de sortida. Cada neurona d‚Äôuna capa est√† connectada a totes les neurones de la capa seg√ºent.\n",
    "\n",
    "- **Funcions d‚ÄôActivaci√≥**: Per introduir no linealitat en el model, s‚Äôutilitzen funcions d‚Äôactivaci√≥ a les neurones, com la funci√≥ sigmoide, ReLU (Rectified Linear Unit) o tangent hiperb√≤lica. Aquestes funcions permeten al MLP capturar patrons complexos en les dades.\n",
    "\n",
    "- **Aprenentatge Supervisat**: L‚Äôentrenament del MLP implica ajustar els pesos de les connexions entre neurones per minimitzar la difer√®ncia entre les sortides produ√Ødes per la xarxa i les sortides desitjades. Aix√≤ es fa utilitzant algorismes d‚Äôaprenentatge supervisat, com el descens del gradient.\n",
    "\n",
    "- **Ajust d‚ÄôHiperpar√†metres**: Igual que altres models d‚Äôaprenentatge autom√†tic, el MLP t√© hiperpar√†metres importants, com el nombre de capes ocultes, el nombre de neurones a cada capa, la funci√≥ d‚Äôactivaci√≥ i la taxa d‚Äôaprenentatge. Sovint, √©s necessari ajustar aquests hiperpar√†metres per obtenir un bon rendiment en una tasca espec√≠fica.\n",
    "\n",
    "- **Generalitzaci√≥**: Un dels desafiaments en l‚Äôentrenament de MLP √©s evitar el sobreajustament (overfitting), on el model s‚Äôadapta massa a les dades d‚Äôentrenament i no generalitza b√© a dades noves. La regularitzaci√≥ i la validaci√≥ creuada s√≥n t√®cniques comunes per abordar aquest problema.\n",
    "\n",
    "En aquest context, el MLP pot ser una excel¬∑lent opci√≥ per modelar patrons complexos que indiquin quan una entrega ser√† premium. No obstant aix√≤, √©s important ajustar i avaluar acuradament el model per garantir que funcioni de manera efectiva en aquesta tasca cr√≠tica.\n",
    "\n",
    "Crear i entrenar un MLP amb diverses capes ocultes amb funci√≥ d‚Äôactivaci√≥ ReLU √©s una excel¬∑lent elecci√≥. La funci√≥ d‚Äôactivaci√≥ ReLU (Rectified Linear Unit) s‚Äôutilitza comunament a capes ocultes de xarxes neuronals a causa de la seva capacitat per introduir no linealitat al model, permetent-li aprendre patrons complexos a les dades.\n",
    "\n",
    "D‚Äôaltra banda, l‚Äôenfocament d‚Äôapilar capes lineals utilitzant la classe `Linear` de PyTorch √©s una forma efica√ß i senzilla de construir models de xarxes neuronals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, X_val, y_val, n_epochs, batch_size):\n",
    "    batch_start = torch.arange(0, len(X_train), batch_size)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    loss_fn = nn.BCELoss()\n",
    "\n",
    "    best_acc = - np.inf\n",
    "    best_weights = None\n",
    "\n",
    "    train_loss_hist = []\n",
    "    train_acc_hist = []\n",
    "    val_loss_hist = []\n",
    "    val_acc_hist = []\n",
    " \n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = []\n",
    "        epoch_acc = []\n",
    "        model.train()\n",
    "        \n",
    "        with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
    "            bar.set_description(f\"Epoch {epoch}\")\n",
    "            for start in bar:\n",
    "\n",
    "                # take a batch\n",
    "                X_batch = X_train[start:start+batch_size]\n",
    "                y_batch = y_train[start:start+batch_size]\n",
    "\n",
    "                # forward pass\n",
    "                y_pred = model(X_batch)\n",
    "                loss = loss_fn(y_pred, y_batch)\n",
    "\n",
    "                # backward pass\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "\n",
    "                # update weights\n",
    "                optimizer.step()\n",
    "\n",
    "                # compute and store metrics\n",
    "                acc = (y_pred.round() == y_batch).float().mean()\n",
    "                epoch_loss.append(float(loss))\n",
    "                epoch_acc.append(float(acc))\n",
    "                bar.set_postfix(\n",
    "                    loss=float(loss),\n",
    "                    acc=float(acc)\n",
    "                )\n",
    "\n",
    "        # Evaluating the model at the end of each epoch\n",
    "        model.eval()\n",
    "        y_pred = model(X_val)\n",
    "        ce = float(loss_fn(y_pred, y_val))\n",
    "        acc = float((y_pred.round() == y_val).float().mean())\n",
    "\n",
    "        train_loss_hist.append(np.mean(epoch_loss))\n",
    "        train_acc_hist.append(np.mean(epoch_acc))\n",
    "        val_loss_hist.append(ce)\n",
    "        val_acc_hist.append(acc)\n",
    "\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "        # print(f\"Epoch {epoch} validation: Cross-entropy={ce:.2f}, Accuracy={acc*100:.1f}%\")\n",
    "\n",
    "    model.load_state_dict(best_weights)\n",
    "    return best_acc, train_loss_hist, val_loss_hist, train_acc_hist, val_acc_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SsMGXeDEfHxA"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementaci√≥:</strong>\n",
    "    \n",
    "La modelitzaci√≥ del MLP la realitzarem amb la biblioteca `PyTorch`. Per fer-ho:\n",
    "\n",
    "1. Comen√ßa creant el model `BinaryServiceLevel`, per al qual √©s necessari crear una classe que hereti de `nn.Module`.\n",
    "2. Al constructor (`__init__`), declara les seg√ºents capes:\n",
    "    - Una capa lineal `nn.Linear` d‚Äôentrada amb una mida de sortida de 19, i una funci√≥ d‚Äôactivaci√≥ ReLU `nn.ReLU`.\n",
    "    - Una capa lineal `nn.Linear` amb una mida de sortida de 19, i una funci√≥ d‚Äôactivaci√≥ ReLU `nn.ReLU`.\n",
    "    - Una capa lineal `nn.Linear` de sortida amb una funci√≥ d‚Äôactivaci√≥ Sigmoid `nn.Sigmoid`.\n",
    "3. Despr√©s, al m√®tode `forward` enlla√ßa les diferents capes i les seves respectives funcions d‚Äôactivaci√≥ en l‚Äôordre definit en el punt anterior.\n",
    "4. No oblidis mostrar el nombre de par√†metres utilitzant el m√®tode `.parameters()` del model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "27hz7RN_fHxA"
   },
   "outputs": [],
   "source": [
    "class BinaryServiceLevelBase(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    " \n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Soluci√≥:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementaci√≥:</strong>\n",
    "  \n",
    "1. Ara √©s el moment d‚Äôentrenar i validar el model aplicant validaci√≥ creuada utilitzant `StratifiedKFold` sobre el conjunt d‚Äôentrenament, amb un valor de k = 5 i `shuffle = True`.\n",
    "2. En cada divisi√≥ (split), el model s‚Äôha d‚Äôentrenar utilitzant la funci√≥ `train_model`. Assegura‚Äôt d‚Äôentrenar amb les dades d‚Äôentrenament i validaci√≥ de cada divisi√≥, establint el nombre d‚Äô√®poques en 15 i la mida del lot en 32.\n",
    "3. En cada iteraci√≥ s‚Äôhan de calcular les seg√ºents m√®triques:\n",
    "    - Calcula l‚Äôexactitud (_accuracy_) per mesurar la precisi√≥ de les prediccions.\n",
    "    - Calcula el valor F1, que √©s una mesura que combina precisi√≥ i sensibilitat.\n",
    "    - Calcula l‚Äô√†rea sota la corba ROC (AUC-ROC) per avaluar el rendiment del model en la classificaci√≥ bin√†ria.\n",
    "4. Finalment, s‚Äôha de mostrar la mitjana de cadascuna de les m√®triques calculades en el punt anterior.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Soluci√≥:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>An√†lisi:</strong>\n",
    "    \n",
    "1. Realitza una an√†lisi dels resultats i decideix si consideres que aquest model √©s acceptable.\n",
    "2. Avalua quina de les mesures de rendiment utilitzades √©s la m√©s apropiada.\n",
    "3. Examina la distribuci√≥ de les classes i planteja una estrat√®gia, si √©s necessari, per assegurar la fiabilitat de l‚Äôestudi realitzat.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<strong>Resposta:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementaci√≥:</strong>\n",
    "  \n",
    "Ara √©s el moment d‚Äôanalitzar la fase d‚Äôentrenament. Per fer-ho:\n",
    " \n",
    "1. Divideix el conjunt d‚Äôentrenament en dos subconjunts: un per a entrenament (train) i un altre per a validaci√≥ (val), assignant el 80% de les dades al conjunt d‚Äôentrenament.\n",
    "2. Entrena el model amb la funci√≥ `model_train`, guardant tots els par√†metres que retorna.\n",
    "3. Crea gr√†fics que mostrin la p√®rdua (`loss`) tant en l‚Äôentrenament com en la validaci√≥ al llarg de les √®poques.\n",
    "4. Finalment, genera gr√†fics que representin l‚Äôexactitud (`accuracy`) en l‚Äôentrenament i la validaci√≥ al llarg de les √®poques.\n",
    "\n",
    "  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Soluci√≥:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>An√†lisi:</strong>\n",
    "\n",
    "Quines conclusions pots obtenir de les gr√†fiques tant de la p√®rdua (`loss`) com de l‚Äôexactitud (`accuracy`) en l‚Äôentrenament i la validaci√≥ al llarg de les √®poques?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<strong>Resposta:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementaci√≥:</strong>\n",
    "  \n",
    "√âs hora d‚Äôavaluar el rendiment del model en el conjunt de prova. Per fer-ho:\n",
    "   \n",
    "1. Realitza la predicci√≥ sobre el conjunt de prova.\n",
    "2. Calcula les m√®triques dels apartats anteriors: exactitud (accuracy), F1 score i corba ROC.\n",
    " \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Soluci√≥:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementaci√≥:</strong>\n",
    "\n",
    "Per analitzar el model entrenat, ens basarem en els [Shapley values](https://en.wikipedia.org/wiki/Shapley_value), que introdueixen l‚Äôexplicaci√≥ de models d‚Äôaprenentatge autom√†tic. L‚Äôobjectiu √©s explicar la predicci√≥ d‚Äôun model calculant la contribuci√≥ de cada caracter√≠stica a la predicci√≥. La descripci√≥ t√®cnica del concepte de SHAP √©s el c√†lcul dels valors de Shapley a partir de la teoria de jocs. En poques paraules, els valors de Shapley s√≥n un m√®tode per mostrar l‚Äôimpacte relatiu de cada caracter√≠stica (o variable) que estem mesurant en el resultat final del model d‚Äôaprenentatge autom√†tic, comparant l‚Äôefecte relatiu de les entrades amb la mitjana.\n",
    "\n",
    "Per calcular els _shap values_:\n",
    "\n",
    "1. Selecciona una mostra de 10000 registres del conjunt d‚Äôentrenament.\n",
    "2. Inicialitza l‚Äô'explainer' `shap.DeepExplainer` amb el model entrenat i la mostra anterior.\n",
    "3. Selecciona una mostra de 400 registres del conjunt d‚Äôentrenament.\n",
    "4. Calcula els _shap values_ utilitzant la mostra anterior.\n",
    "5. Defineix i mostra un DataFrame amb tres columnes:\n",
    "   - Mitjana aritm√®tica del valor absolut dels valors.\n",
    "   - Desviaci√≥ t√≠pica del valor absolut dels valors.\n",
    "   - Nom de l‚Äôatribut descriptiu.\n",
    "6. Mostra la representaci√≥ gr√†fica dels valors utilitzant la biblioteca SHAP.\n",
    " \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Soluci√≥:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>An√†lisi:</strong>\n",
    "    \n",
    "Relaciona la interpretaci√≥ dels _shap values_ amb l‚Äôan√†lisi exploratori de les dades realitzat a l‚Äôexercici 2.2.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<strong>Resposta:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>An√†lisi:</strong>\n",
    "    \n",
    "Imagina que calculem els _shap values_ per a cada divisi√≥ (split) en l‚Äôexercici en qu√® vam entrenar el model utilitzant validaci√≥ creuada. \n",
    "- Els an√†lisis dels diferents models haurien de ser similars? Per qu√® o per qu√® no?\n",
    "- Qu√® indicaria si l‚Äôan√†lisi de cada model varia molt d‚Äôun a l‚Äôaltre?\n",
    "- Quins usos addicionals podem donar als _shap values_?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<strong>Resposta:</strong>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
